{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GLxgv9OSFqYi"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/LayoutQT')\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84QeWKhKKG_S"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXfagt2R4ysX"},"outputs":[],"source":["import torch\n","\n","# Create torch dataset\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels=None):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        if self.labels:\n","            item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqfZpHuo4oPd"},"outputs":[],"source":["def process_data_for_bert(data):\n","\n","    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","    X_tokenized = tokenizer(list(data['text']), padding=True, truncation=True, max_length=512)\n","    y = list(data['label'])\n","    \n","    dataset = Dataset(X_tokenized, y)\n","\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DVekXFaKy38u"},"outputs":[],"source":["from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import TrainingArguments, Trainer\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoModelForMaskedLM\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import train_test_split\n","\n","def runBert(df_train_dataset, df_val_dataset, df_test_dataset):\n","    \n","    batch_size=16\n","\n","    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=16)\n","    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=False )\n","     \n","    train_dataset = process_data_for_bert(df_train_dataset)\n","    val_dataset = process_data_for_bert(df_val_dataset)\n","    test_dataset = process_data_for_bert(df_test_dataset)\n","\n","    # ----- 2. Fine-tune pretrained model -----#\n","    # Define Trainer parameters\n","    def compute_metrics(p):\n","        \n","        pred, labels = p\n","        pred = np.argmax(pred, axis=1)\n","\n","        accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","        recall = recall_score(y_true=labels, y_pred=pred, average='micro')\n","        precision = precision_score(y_true=labels, y_pred=pred, average='micro')\n","        f1 = f1_score(y_true=labels, y_pred=pred, average='micro')\n","\n","        return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n","\n","    # Define Trainer\n","    args = TrainingArguments(\n","        \"./model/layoutqt_rvlcdip\",\n","        evaluation_strategy = \"epoch\",\n","        save_strategy = \"epoch\",\n","        learning_rate=2e-5,\n","        per_device_train_batch_size=batch_size,\n","        per_device_eval_batch_size=batch_size,\n","        num_train_epochs=10,\n","        weight_decay=0.01,\n","        load_best_model_at_end=True,\n","        metric_for_best_model='f1'\n","      # optim=\"adamw_torch\"\n","    )\n","\n","    def model_init():\n","        return model\n","\n","    trainer = Trainer(\n","        model_init=model_init,\n","        args=args,\n","        train_dataset=train_dataset,\n","        eval_dataset=val_dataset,\n","        tokenizer=tokenizer,\n","        compute_metrics=compute_metrics\n","    )\n","\n","    # New code - wrap collator in a dictionary\n","    #data_collator = trainer.data_collator\n","    #trainer.data_collator = lambda data: dict(data_collator(data))\n","    # End new code\n","\n","    trainer.train()\n","\n","    # Make prediction\n","    raw_pred, _, _ = trainer.predict(test_dataset)\n","\n","    # Preprocess raw predictions\n","    y_pred = np.argmax(raw_pred, axis=1)\n","\n","    return y_pred\n","    #return roc_auc_score(df_test_dataset['class'], y_pred), f1_score(df_test_dataset['class'], y_pred, average='macro')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUTqnUToLjAH"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","             \n","df_train = pd.read_csv(\"./input/rvlcdip/train.csv\")\n","#df_train = df_train[0:10000] \n","\n","df_val = pd.read_csv(\"./input/rvlcdip/val.csv\")\n","#df_val = df_val[0:2000]\n","\n","df_test = pd.read_csv(\"./input/rvlcdip/test.csv\")\n","#df_test = df_test[0:2000]\n","\n","df_train['text'] = df_train['text'].apply(lambda x: str(x))\n","df_test['text'] = df_test['text'].apply(lambda x: str(x))\n","\n","df_train['label'] = df_train['label'].apply(lambda x: int(x))\n","df_test['label'] = df_test['label'].apply(lambda x: int(x))\n","\n","y_pred = runBert(df_train, df_val, df_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T0Oo3lP83iyn"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.metrics import roc_auc_score\n","\n","print(\"Accuracy:\", accuracy_score(df_test['label'], y_pred))\n","print(\"F1:\", f1_score(df_test['label'], y_pred, average='micro'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r7OmwUESA9Ab"},"outputs":[],"source":["print(classification_report(df_test['label'], y_pred))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}