{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26494,"status":"ok","timestamp":1666663639498,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"},"user_tz":180},"id":"GLxgv9OSFqYi","outputId":"a5b83958-283d-41f3-d1f1-3132ec8dcb73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/LayoutQT')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84QeWKhKKG_S","executionInfo":{"status":"ok","timestamp":1666663649166,"user_tz":180,"elapsed":9673,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"7c4fddc1-d6e6-4264-ae50-97c89d4dea28"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 37.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 68.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 55.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xXfagt2R4ysX","executionInfo":{"status":"ok","timestamp":1666663651504,"user_tz":180,"elapsed":2342,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"outputs":[],"source":["import torch\n","\n","# Create torch dataset\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels=None):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        if self.labels:\n","            item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"oqfZpHuo4oPd","executionInfo":{"status":"ok","timestamp":1666663651505,"user_tz":180,"elapsed":9,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"outputs":[],"source":["def process_data_for_bert(data):\n","\n","    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","    X_tokenized = tokenizer(list(data['text']), padding=True, truncation=True, max_length=512)\n","    y = list(data['class'])\n","    \n","    dataset = Dataset(X_tokenized, y)\n","\n","    return dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"DVekXFaKy38u","executionInfo":{"status":"ok","timestamp":1666663654745,"user_tz":180,"elapsed":3247,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"outputs":[],"source":["from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import TrainingArguments, Trainer\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoModelForMaskedLM\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import train_test_split\n","\n","def runBert(df_train_dataset, df_test_dataset):\n","    \n","    batch_size=16\n","\n","    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=False )\n","\n","\n","    X_train, X_val, y_train, y_val = train_test_split(df_train_dataset['text'], df_train_dataset['class'], \n","                                                    test_size=0.2, \n","                                                    random_state=42)\n","\n","\n","    train_dataset = pd.DataFrame({'text':X_train, 'class':y_train})\n","    val_dataset = pd.DataFrame({'text':X_val, 'class':y_val})\n","\n","    \n","    \n","    train_dataset = process_data_for_bert(train_dataset)\n","    val_dataset = process_data_for_bert(val_dataset)\n","    test_dataset = process_data_for_bert(df_test_dataset)\n","\n","    # ----- 2. Fine-tune pretrained model -----#\n","    # Define Trainer parameters\n","    def compute_metrics(p):\n","        \n","        pred, labels = p\n","        pred = np.argmax(pred, axis=1)\n","\n","        accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","        recall = recall_score(y_true=labels, y_pred=pred)\n","        precision = precision_score(y_true=labels, y_pred=pred)\n","        f1 = f1_score(y_true=labels, y_pred=pred)\n","\n","        return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n","\n","    # Define Trainer\n","    args = TrainingArguments(\n","        \"./model/layoutqt\",\n","        evaluation_strategy = \"epoch\",\n","        save_strategy = \"epoch\",\n","        learning_rate=2e-5,\n","        per_device_train_batch_size=batch_size,\n","        per_device_eval_batch_size=batch_size,\n","        num_train_epochs=100,\n","        weight_decay=0.01,\n","        load_best_model_at_end=True,\n","        metric_for_best_model='f1'\n","      # optim=\"adamw_torch\"\n","    )\n","\n","    def model_init():\n","        return model\n","\n","    trainer = Trainer(\n","        model_init=model_init,\n","        args=args,\n","        train_dataset=train_dataset,\n","        eval_dataset=val_dataset,\n","        tokenizer=tokenizer,\n","        compute_metrics=compute_metrics\n","    )\n","\n","    # New code - wrap collator in a dictionary\n","    #data_collator = trainer.data_collator\n","    #trainer.data_collator = lambda data: dict(data_collator(data))\n","    # End new code\n","\n","    trainer.train()\n","\n","    # Make prediction\n","    raw_pred, _, _ = trainer.predict(test_dataset)\n","\n","    # Preprocess raw predictions\n","    y_pred = np.argmax(raw_pred, axis=1)\n","\n","    return y_pred\n","    #return roc_auc_score(df_test_dataset['class'], y_pred), f1_score(df_test_dataset['class'], y_pred, average='macro')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"nUTqnUToLjAH","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3e7541435b6e4757a19bd0cb0b572304","ff89f51d8fe345f18e34e9e2b94888a0","e46b9cbd407842b4b91c8fd0c5a17816","d31044c808d54663a20841ddc95c05e5","01f62a059dbc42f2ae35d5fa69533fd9","c3c3f7194e2c41ff864849b862ce12f5","a73cc058dd2645bd971df75128aaa09c","e472b7e1811741f2a36ddf11f9163ef9","85b42b85b8a54fd58cb4744c6127d98b","419dc7dd615841a4809780c3d822df0d","98a8389f959445b0b331a7fc226062cf","b0e1520316c2449dae75697341f986a9","becd992ff540439794ebdd8984ac5115","5afa36f2f88f4b22a0ae4ce6d80462be","457ccd60b7754b2097a6d20ce6115a59","a9880e685edc4e5abe8b4b9b2e3f88e6","dcedfeeb59234e83871188e09111c0d0","325e04e793aa44ec8b028fb7e3836a9d","bfa7ab8f8c6140a6982de48956d82529","7d94cf27a4a44b09aa832e057e22b4c4","165385d7cdf04a8cbe030a7ae2a0a787","06790d64ea7f428cbddb0479c3b5321e","710b50ff516746c9aba37e7e5d1697ae","b04f13eda4c1414fb90567cf67e80f93","95e0578a15324f069df02c404ba7eaf7","a8347f47144f4b69b6409c7b7fbe15a7","a04b062070134097bbfa3276e20dd77b","14626f5e711940b4b8e87c505062bf83","78f06fe2ea414749b33e90122cb0add4","cfb6e91677ef48fcb812dc9d9187949b","0fbecae17b614bc5aef1f7d71893af8e","d02ff55ded514843ba9569450d99cbfb","e5b1772d2d174dfaa3821658f1d24bba","b025072ad4e2434bb83d618442dcf7ff","1b570912d2334c3091ea72bbbec4648e","4b9f9b97197c4f4c817d05cceb10bfa3","cfb466074e6b435496b9c5cb4916b24a","62802ba3a83545f78b058d6364a0c896","2b754d51c74949edb71aee79d377cacb","5cc49d8c932f4a2ab4229b125d450392","fb458ab0ac4c49a094fdb451b52efa93","9053115ca24c4915bf77554baafe4a2b","fa63e5163af1494dafec36d64cde3531","54919ffea4c64c6c9868b2220582012c"]},"outputId":"f1eda8d4-3e0e-470f-bff8-29a1fa794c84","executionInfo":{"status":"ok","timestamp":1666672864849,"user_tz":180,"elapsed":9210121,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e7541435b6e4757a19bd0cb0b572304"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0e1520316c2449dae75697341f986a9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"710b50ff516746c9aba37e7e5d1697ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b025072ad4e2434bb83d618442dcf7ff"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 824\n","  Num Epochs = 100\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5200\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5200' max='5200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5200/5200 2:32:28, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.458616</td>\n","      <td>0.816425</td>\n","      <td>0.778571</td>\n","      <td>0.939655</td>\n","      <td>0.851563</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.345661</td>\n","      <td>0.888889</td>\n","      <td>0.897436</td>\n","      <td>0.905172</td>\n","      <td>0.901288</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.342562</td>\n","      <td>0.874396</td>\n","      <td>0.868852</td>\n","      <td>0.913793</td>\n","      <td>0.890756</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.416175</td>\n","      <td>0.874396</td>\n","      <td>0.894737</td>\n","      <td>0.879310</td>\n","      <td>0.886957</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.484029</td>\n","      <td>0.869565</td>\n","      <td>0.861789</td>\n","      <td>0.913793</td>\n","      <td>0.887029</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>No log</td>\n","      <td>0.568168</td>\n","      <td>0.864734</td>\n","      <td>0.849206</td>\n","      <td>0.922414</td>\n","      <td>0.884298</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>No log</td>\n","      <td>0.660541</td>\n","      <td>0.845411</td>\n","      <td>0.828125</td>\n","      <td>0.913793</td>\n","      <td>0.868852</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>No log</td>\n","      <td>0.766773</td>\n","      <td>0.835749</td>\n","      <td>0.805970</td>\n","      <td>0.931034</td>\n","      <td>0.864000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>No log</td>\n","      <td>0.757813</td>\n","      <td>0.850242</td>\n","      <td>0.851240</td>\n","      <td>0.887931</td>\n","      <td>0.869198</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.194600</td>\n","      <td>0.749195</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.194600</td>\n","      <td>0.824271</td>\n","      <td>0.855072</td>\n","      <td>0.820896</td>\n","      <td>0.948276</td>\n","      <td>0.880000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.194600</td>\n","      <td>0.852034</td>\n","      <td>0.859903</td>\n","      <td>0.865546</td>\n","      <td>0.887931</td>\n","      <td>0.876596</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.194600</td>\n","      <td>0.970033</td>\n","      <td>0.845411</td>\n","      <td>0.855932</td>\n","      <td>0.870690</td>\n","      <td>0.863248</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.194600</td>\n","      <td>0.889615</td>\n","      <td>0.874396</td>\n","      <td>0.887931</td>\n","      <td>0.887931</td>\n","      <td>0.887931</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.194600</td>\n","      <td>0.989827</td>\n","      <td>0.845411</td>\n","      <td>0.844262</td>\n","      <td>0.887931</td>\n","      <td>0.865546</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.194600</td>\n","      <td>1.005167</td>\n","      <td>0.855072</td>\n","      <td>0.852459</td>\n","      <td>0.896552</td>\n","      <td>0.873950</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.194600</td>\n","      <td>1.025977</td>\n","      <td>0.855072</td>\n","      <td>0.852459</td>\n","      <td>0.896552</td>\n","      <td>0.873950</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.194600</td>\n","      <td>1.139800</td>\n","      <td>0.850242</td>\n","      <td>0.834646</td>\n","      <td>0.913793</td>\n","      <td>0.872428</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.194600</td>\n","      <td>1.149485</td>\n","      <td>0.850242</td>\n","      <td>0.851240</td>\n","      <td>0.887931</td>\n","      <td>0.869198</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.015300</td>\n","      <td>1.165876</td>\n","      <td>0.845411</td>\n","      <td>0.838710</td>\n","      <td>0.896552</td>\n","      <td>0.866667</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.015300</td>\n","      <td>1.171864</td>\n","      <td>0.845411</td>\n","      <td>0.838710</td>\n","      <td>0.896552</td>\n","      <td>0.866667</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.015300</td>\n","      <td>1.169125</td>\n","      <td>0.855072</td>\n","      <td>0.846774</td>\n","      <td>0.905172</td>\n","      <td>0.875000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.015300</td>\n","      <td>1.185887</td>\n","      <td>0.850242</td>\n","      <td>0.845528</td>\n","      <td>0.896552</td>\n","      <td>0.870293</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.015300</td>\n","      <td>1.198597</td>\n","      <td>0.850242</td>\n","      <td>0.845528</td>\n","      <td>0.896552</td>\n","      <td>0.870293</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.015300</td>\n","      <td>1.210807</td>\n","      <td>0.855072</td>\n","      <td>0.846774</td>\n","      <td>0.905172</td>\n","      <td>0.875000</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.015300</td>\n","      <td>1.235777</td>\n","      <td>0.850242</td>\n","      <td>0.840000</td>\n","      <td>0.905172</td>\n","      <td>0.871369</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.015300</td>\n","      <td>1.252062</td>\n","      <td>0.850242</td>\n","      <td>0.840000</td>\n","      <td>0.905172</td>\n","      <td>0.871369</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.015300</td>\n","      <td>1.256104</td>\n","      <td>0.850242</td>\n","      <td>0.840000</td>\n","      <td>0.905172</td>\n","      <td>0.871369</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.002900</td>\n","      <td>1.262848</td>\n","      <td>0.850242</td>\n","      <td>0.840000</td>\n","      <td>0.905172</td>\n","      <td>0.871369</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.002900</td>\n","      <td>1.271360</td>\n","      <td>0.850242</td>\n","      <td>0.840000</td>\n","      <td>0.905172</td>\n","      <td>0.871369</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.002900</td>\n","      <td>1.282623</td>\n","      <td>0.850242</td>\n","      <td>0.840000</td>\n","      <td>0.905172</td>\n","      <td>0.871369</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.002900</td>\n","      <td>1.289802</td>\n","      <td>0.850242</td>\n","      <td>0.840000</td>\n","      <td>0.905172</td>\n","      <td>0.871369</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.002900</td>\n","      <td>1.293749</td>\n","      <td>0.850242</td>\n","      <td>0.840000</td>\n","      <td>0.905172</td>\n","      <td>0.871369</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.002900</td>\n","      <td>1.298748</td>\n","      <td>0.850242</td>\n","      <td>0.840000</td>\n","      <td>0.905172</td>\n","      <td>0.871369</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.002900</td>\n","      <td>1.305621</td>\n","      <td>0.850242</td>\n","      <td>0.840000</td>\n","      <td>0.905172</td>\n","      <td>0.871369</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.002900</td>\n","      <td>1.302739</td>\n","      <td>0.855072</td>\n","      <td>0.846774</td>\n","      <td>0.905172</td>\n","      <td>0.875000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.002900</td>\n","      <td>1.285891</td>\n","      <td>0.855072</td>\n","      <td>0.846774</td>\n","      <td>0.905172</td>\n","      <td>0.875000</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.002900</td>\n","      <td>1.106587</td>\n","      <td>0.845411</td>\n","      <td>0.850000</td>\n","      <td>0.879310</td>\n","      <td>0.864407</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.005400</td>\n","      <td>1.147829</td>\n","      <td>0.850242</td>\n","      <td>0.845528</td>\n","      <td>0.896552</td>\n","      <td>0.870293</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.005400</td>\n","      <td>1.117605</td>\n","      <td>0.859903</td>\n","      <td>0.853659</td>\n","      <td>0.905172</td>\n","      <td>0.878661</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.005400</td>\n","      <td>1.199321</td>\n","      <td>0.855072</td>\n","      <td>0.852459</td>\n","      <td>0.896552</td>\n","      <td>0.873950</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.005400</td>\n","      <td>1.039245</td>\n","      <td>0.879227</td>\n","      <td>0.858268</td>\n","      <td>0.939655</td>\n","      <td>0.897119</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.005400</td>\n","      <td>1.130370</td>\n","      <td>0.874396</td>\n","      <td>0.846154</td>\n","      <td>0.948276</td>\n","      <td>0.894309</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.005400</td>\n","      <td>1.182822</td>\n","      <td>0.859903</td>\n","      <td>0.848000</td>\n","      <td>0.913793</td>\n","      <td>0.879668</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.005400</td>\n","      <td>1.112392</td>\n","      <td>0.869565</td>\n","      <td>0.900901</td>\n","      <td>0.862069</td>\n","      <td>0.881057</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.005400</td>\n","      <td>1.267781</td>\n","      <td>0.850242</td>\n","      <td>0.824427</td>\n","      <td>0.931034</td>\n","      <td>0.874494</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.005400</td>\n","      <td>1.209406</td>\n","      <td>0.850242</td>\n","      <td>0.857143</td>\n","      <td>0.879310</td>\n","      <td>0.868085</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.005400</td>\n","      <td>1.224950</td>\n","      <td>0.850242</td>\n","      <td>0.840000</td>\n","      <td>0.905172</td>\n","      <td>0.871369</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.010700</td>\n","      <td>1.223025</td>\n","      <td>0.845411</td>\n","      <td>0.838710</td>\n","      <td>0.896552</td>\n","      <td>0.866667</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.010700</td>\n","      <td>1.154772</td>\n","      <td>0.859903</td>\n","      <td>0.859504</td>\n","      <td>0.896552</td>\n","      <td>0.877637</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.010700</td>\n","      <td>1.201033</td>\n","      <td>0.859903</td>\n","      <td>0.842520</td>\n","      <td>0.922414</td>\n","      <td>0.880658</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.010700</td>\n","      <td>1.058359</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.010700</td>\n","      <td>1.074477</td>\n","      <td>0.864734</td>\n","      <td>0.866667</td>\n","      <td>0.896552</td>\n","      <td>0.881356</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.010700</td>\n","      <td>1.083695</td>\n","      <td>0.864734</td>\n","      <td>0.866667</td>\n","      <td>0.896552</td>\n","      <td>0.881356</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.010700</td>\n","      <td>1.079324</td>\n","      <td>0.864734</td>\n","      <td>0.866667</td>\n","      <td>0.896552</td>\n","      <td>0.881356</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.010700</td>\n","      <td>1.083258</td>\n","      <td>0.864734</td>\n","      <td>0.866667</td>\n","      <td>0.896552</td>\n","      <td>0.881356</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.010700</td>\n","      <td>1.087300</td>\n","      <td>0.869565</td>\n","      <td>0.867769</td>\n","      <td>0.905172</td>\n","      <td>0.886076</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.002600</td>\n","      <td>1.092299</td>\n","      <td>0.864734</td>\n","      <td>0.860656</td>\n","      <td>0.905172</td>\n","      <td>0.882353</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.002600</td>\n","      <td>1.104855</td>\n","      <td>0.859903</td>\n","      <td>0.853659</td>\n","      <td>0.905172</td>\n","      <td>0.878661</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.002600</td>\n","      <td>1.119359</td>\n","      <td>0.864734</td>\n","      <td>0.854839</td>\n","      <td>0.913793</td>\n","      <td>0.883333</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.002600</td>\n","      <td>1.114006</td>\n","      <td>0.864734</td>\n","      <td>0.854839</td>\n","      <td>0.913793</td>\n","      <td>0.883333</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.002600</td>\n","      <td>1.109769</td>\n","      <td>0.864734</td>\n","      <td>0.854839</td>\n","      <td>0.913793</td>\n","      <td>0.883333</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.002600</td>\n","      <td>1.125003</td>\n","      <td>0.864734</td>\n","      <td>0.854839</td>\n","      <td>0.913793</td>\n","      <td>0.883333</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.002600</td>\n","      <td>1.104498</td>\n","      <td>0.864734</td>\n","      <td>0.854839</td>\n","      <td>0.913793</td>\n","      <td>0.883333</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.002600</td>\n","      <td>1.112229</td>\n","      <td>0.864734</td>\n","      <td>0.854839</td>\n","      <td>0.913793</td>\n","      <td>0.883333</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.002600</td>\n","      <td>1.115251</td>\n","      <td>0.869565</td>\n","      <td>0.861789</td>\n","      <td>0.913793</td>\n","      <td>0.887029</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.002600</td>\n","      <td>1.119559</td>\n","      <td>0.864734</td>\n","      <td>0.854839</td>\n","      <td>0.913793</td>\n","      <td>0.883333</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.002300</td>\n","      <td>1.127844</td>\n","      <td>0.864734</td>\n","      <td>0.854839</td>\n","      <td>0.913793</td>\n","      <td>0.883333</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.002300</td>\n","      <td>1.130078</td>\n","      <td>0.864734</td>\n","      <td>0.860656</td>\n","      <td>0.905172</td>\n","      <td>0.882353</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.002300</td>\n","      <td>1.142825</td>\n","      <td>0.864734</td>\n","      <td>0.854839</td>\n","      <td>0.913793</td>\n","      <td>0.883333</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.002300</td>\n","      <td>1.134529</td>\n","      <td>0.864734</td>\n","      <td>0.860656</td>\n","      <td>0.905172</td>\n","      <td>0.882353</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.002300</td>\n","      <td>1.126554</td>\n","      <td>0.874396</td>\n","      <td>0.875000</td>\n","      <td>0.905172</td>\n","      <td>0.889831</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.002300</td>\n","      <td>1.129472</td>\n","      <td>0.869565</td>\n","      <td>0.867769</td>\n","      <td>0.905172</td>\n","      <td>0.886076</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.002300</td>\n","      <td>1.131333</td>\n","      <td>0.874396</td>\n","      <td>0.875000</td>\n","      <td>0.905172</td>\n","      <td>0.889831</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.002300</td>\n","      <td>1.167508</td>\n","      <td>0.864734</td>\n","      <td>0.872881</td>\n","      <td>0.887931</td>\n","      <td>0.880342</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.002300</td>\n","      <td>1.158539</td>\n","      <td>0.879227</td>\n","      <td>0.902655</td>\n","      <td>0.879310</td>\n","      <td>0.890830</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.002600</td>\n","      <td>1.172356</td>\n","      <td>0.874396</td>\n","      <td>0.894737</td>\n","      <td>0.879310</td>\n","      <td>0.886957</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.002600</td>\n","      <td>1.181175</td>\n","      <td>0.864734</td>\n","      <td>0.879310</td>\n","      <td>0.879310</td>\n","      <td>0.879310</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.002600</td>\n","      <td>1.219140</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.002600</td>\n","      <td>1.221347</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.002600</td>\n","      <td>1.220484</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.002600</td>\n","      <td>1.222385</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.002600</td>\n","      <td>1.222886</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.002600</td>\n","      <td>1.224965</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.002600</td>\n","      <td>1.227510</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.002600</td>\n","      <td>1.224750</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.002400</td>\n","      <td>1.225370</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.002400</td>\n","      <td>1.223812</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.002400</td>\n","      <td>1.225184</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.002400</td>\n","      <td>1.227589</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.002400</td>\n","      <td>1.226739</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.002400</td>\n","      <td>1.226719</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.002400</td>\n","      <td>1.225890</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.002400</td>\n","      <td>1.226150</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.002400</td>\n","      <td>1.227076</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.002400</td>\n","      <td>1.227485</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.002300</td>\n","      <td>1.228134</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.002300</td>\n","      <td>1.228488</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.002300</td>\n","      <td>1.228030</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.002300</td>\n","      <td>1.228001</td>\n","      <td>0.869565</td>\n","      <td>0.873950</td>\n","      <td>0.896552</td>\n","      <td>0.885106</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-52\n","Configuration saved in ./model/layoutqt/checkpoint-52/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-52/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-52/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-52/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-104\n","Configuration saved in ./model/layoutqt/checkpoint-104/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-104/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-104/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-104/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-156\n","Configuration saved in ./model/layoutqt/checkpoint-156/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-156/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-156/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-156/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-208\n","Configuration saved in ./model/layoutqt/checkpoint-208/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-208/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-208/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-208/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-260\n","Configuration saved in ./model/layoutqt/checkpoint-260/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-260/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-260/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-260/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-312\n","Configuration saved in ./model/layoutqt/checkpoint-312/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-312/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-312/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-312/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-364\n","Configuration saved in ./model/layoutqt/checkpoint-364/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-364/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-364/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-364/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-416\n","Configuration saved in ./model/layoutqt/checkpoint-416/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-416/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-416/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-416/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-468\n","Configuration saved in ./model/layoutqt/checkpoint-468/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-468/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-468/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-468/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-520\n","Configuration saved in ./model/layoutqt/checkpoint-520/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-520/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-520/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-520/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-572\n","Configuration saved in ./model/layoutqt/checkpoint-572/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-572/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-572/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-572/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-624\n","Configuration saved in ./model/layoutqt/checkpoint-624/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-624/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-624/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-624/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-676\n","Configuration saved in ./model/layoutqt/checkpoint-676/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-676/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-676/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-676/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-728\n","Configuration saved in ./model/layoutqt/checkpoint-728/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-728/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-728/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-728/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-780\n","Configuration saved in ./model/layoutqt/checkpoint-780/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-780/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-780/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-780/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-832\n","Configuration saved in ./model/layoutqt/checkpoint-832/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-832/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-832/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-832/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-884\n","Configuration saved in ./model/layoutqt/checkpoint-884/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-884/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-884/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-884/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-936\n","Configuration saved in ./model/layoutqt/checkpoint-936/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-936/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-936/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-936/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-988\n","Configuration saved in ./model/layoutqt/checkpoint-988/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-988/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-988/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-988/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1040\n","Configuration saved in ./model/layoutqt/checkpoint-1040/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1040/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1040/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1040/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1092\n","Configuration saved in ./model/layoutqt/checkpoint-1092/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1092/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1092/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1092/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1144\n","Configuration saved in ./model/layoutqt/checkpoint-1144/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1144/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1144/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1144/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1196\n","Configuration saved in ./model/layoutqt/checkpoint-1196/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1196/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1196/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1196/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1248\n","Configuration saved in ./model/layoutqt/checkpoint-1248/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1248/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1248/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1248/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1300\n","Configuration saved in ./model/layoutqt/checkpoint-1300/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1300/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1300/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1300/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1352\n","Configuration saved in ./model/layoutqt/checkpoint-1352/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1352/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1352/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1352/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1404\n","Configuration saved in ./model/layoutqt/checkpoint-1404/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1404/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1404/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1404/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1456\n","Configuration saved in ./model/layoutqt/checkpoint-1456/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1456/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1456/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1456/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1508\n","Configuration saved in ./model/layoutqt/checkpoint-1508/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1508/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1508/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1508/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1560\n","Configuration saved in ./model/layoutqt/checkpoint-1560/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1560/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1560/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1560/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1612\n","Configuration saved in ./model/layoutqt/checkpoint-1612/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1612/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1612/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1612/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1664\n","Configuration saved in ./model/layoutqt/checkpoint-1664/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1664/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1664/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1664/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1716\n","Configuration saved in ./model/layoutqt/checkpoint-1716/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1716/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1716/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1716/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1768\n","Configuration saved in ./model/layoutqt/checkpoint-1768/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1768/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1768/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1768/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1820\n","Configuration saved in ./model/layoutqt/checkpoint-1820/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1820/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1820/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1820/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1872\n","Configuration saved in ./model/layoutqt/checkpoint-1872/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1872/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1872/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1872/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1924\n","Configuration saved in ./model/layoutqt/checkpoint-1924/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1924/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1924/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1924/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1976\n","Configuration saved in ./model/layoutqt/checkpoint-1976/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1976/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1976/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1976/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2028\n","Configuration saved in ./model/layoutqt/checkpoint-2028/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2028/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2028/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2028/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2080\n","Configuration saved in ./model/layoutqt/checkpoint-2080/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2080/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2080/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2080/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2132\n","Configuration saved in ./model/layoutqt/checkpoint-2132/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2132/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2132/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2132/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2184\n","Configuration saved in ./model/layoutqt/checkpoint-2184/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2184/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2184/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2184/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2236\n","Configuration saved in ./model/layoutqt/checkpoint-2236/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2236/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2236/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2236/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2288\n","Configuration saved in ./model/layoutqt/checkpoint-2288/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2288/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2288/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2288/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2340\n","Configuration saved in ./model/layoutqt/checkpoint-2340/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2340/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2340/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2340/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2392\n","Configuration saved in ./model/layoutqt/checkpoint-2392/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2392/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2392/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2392/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2444\n","Configuration saved in ./model/layoutqt/checkpoint-2444/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2444/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2444/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2444/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2496\n","Configuration saved in ./model/layoutqt/checkpoint-2496/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2496/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2496/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2496/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2548\n","Configuration saved in ./model/layoutqt/checkpoint-2548/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2548/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2548/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2548/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2600\n","Configuration saved in ./model/layoutqt/checkpoint-2600/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2600/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2600/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2600/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2652\n","Configuration saved in ./model/layoutqt/checkpoint-2652/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2652/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2652/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2652/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2704\n","Configuration saved in ./model/layoutqt/checkpoint-2704/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2704/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2704/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2704/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2756\n","Configuration saved in ./model/layoutqt/checkpoint-2756/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2756/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2756/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2756/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2808\n","Configuration saved in ./model/layoutqt/checkpoint-2808/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2808/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2808/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2808/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2860\n","Configuration saved in ./model/layoutqt/checkpoint-2860/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2860/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2860/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2860/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2912\n","Configuration saved in ./model/layoutqt/checkpoint-2912/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2912/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2912/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2912/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2964\n","Configuration saved in ./model/layoutqt/checkpoint-2964/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2964/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2964/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2964/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3016\n","Configuration saved in ./model/layoutqt/checkpoint-3016/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3016/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3016/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3016/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3068\n","Configuration saved in ./model/layoutqt/checkpoint-3068/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3068/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3068/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3068/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3120\n","Configuration saved in ./model/layoutqt/checkpoint-3120/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3120/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3120/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3120/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3172\n","Configuration saved in ./model/layoutqt/checkpoint-3172/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3172/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3172/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3172/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3224\n","Configuration saved in ./model/layoutqt/checkpoint-3224/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3224/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3224/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3224/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3276\n","Configuration saved in ./model/layoutqt/checkpoint-3276/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3276/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3276/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3276/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3328\n","Configuration saved in ./model/layoutqt/checkpoint-3328/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3328/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3328/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3328/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3380\n","Configuration saved in ./model/layoutqt/checkpoint-3380/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3380/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3380/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3380/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3432\n","Configuration saved in ./model/layoutqt/checkpoint-3432/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3432/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3432/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3432/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3484\n","Configuration saved in ./model/layoutqt/checkpoint-3484/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3484/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3484/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3484/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3536\n","Configuration saved in ./model/layoutqt/checkpoint-3536/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3536/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3536/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3536/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3588\n","Configuration saved in ./model/layoutqt/checkpoint-3588/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3588/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3588/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3588/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3640\n","Configuration saved in ./model/layoutqt/checkpoint-3640/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3640/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3640/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3640/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3692\n","Configuration saved in ./model/layoutqt/checkpoint-3692/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3692/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3692/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3692/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3744\n","Configuration saved in ./model/layoutqt/checkpoint-3744/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3744/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3744/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3744/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3796\n","Configuration saved in ./model/layoutqt/checkpoint-3796/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3796/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3796/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3796/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3848\n","Configuration saved in ./model/layoutqt/checkpoint-3848/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3848/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3848/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3848/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3900\n","Configuration saved in ./model/layoutqt/checkpoint-3900/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3900/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3900/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3900/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3952\n","Configuration saved in ./model/layoutqt/checkpoint-3952/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3952/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3952/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3952/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4004\n","Configuration saved in ./model/layoutqt/checkpoint-4004/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4004/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4004/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4004/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4056\n","Configuration saved in ./model/layoutqt/checkpoint-4056/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4056/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4056/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4056/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4108\n","Configuration saved in ./model/layoutqt/checkpoint-4108/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4108/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4108/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4108/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4160\n","Configuration saved in ./model/layoutqt/checkpoint-4160/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4160/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4160/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4160/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4212\n","Configuration saved in ./model/layoutqt/checkpoint-4212/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4212/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4212/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4212/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4264\n","Configuration saved in ./model/layoutqt/checkpoint-4264/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4264/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4264/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4264/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4316\n","Configuration saved in ./model/layoutqt/checkpoint-4316/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4316/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4316/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4316/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4368\n","Configuration saved in ./model/layoutqt/checkpoint-4368/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4368/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4368/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4368/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4420\n","Configuration saved in ./model/layoutqt/checkpoint-4420/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4420/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4420/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4420/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4472\n","Configuration saved in ./model/layoutqt/checkpoint-4472/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4472/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4472/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4472/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4524\n","Configuration saved in ./model/layoutqt/checkpoint-4524/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4524/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4524/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4524/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4576\n","Configuration saved in ./model/layoutqt/checkpoint-4576/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4576/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4576/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4576/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4628\n","Configuration saved in ./model/layoutqt/checkpoint-4628/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4628/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4628/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4628/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4680\n","Configuration saved in ./model/layoutqt/checkpoint-4680/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4680/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4680/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4680/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4732\n","Configuration saved in ./model/layoutqt/checkpoint-4732/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4732/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4732/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4732/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4784\n","Configuration saved in ./model/layoutqt/checkpoint-4784/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4784/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4784/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4784/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4836\n","Configuration saved in ./model/layoutqt/checkpoint-4836/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4836/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4836/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4836/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4888\n","Configuration saved in ./model/layoutqt/checkpoint-4888/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4888/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4888/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4888/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4940\n","Configuration saved in ./model/layoutqt/checkpoint-4940/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4940/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4940/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4940/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4992\n","Configuration saved in ./model/layoutqt/checkpoint-4992/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4992/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4992/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4992/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5044\n","Configuration saved in ./model/layoutqt/checkpoint-5044/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5044/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5044/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5044/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5096\n","Configuration saved in ./model/layoutqt/checkpoint-5096/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5096/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5096/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5096/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5148\n","Configuration saved in ./model/layoutqt/checkpoint-5148/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5148/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5148/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5148/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 16\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5200\n","Configuration saved in ./model/layoutqt/checkpoint-5200/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5200/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5200/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5200/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from ./model/layoutqt/checkpoint-104 (score: 0.9012875536480686).\n","***** Running Prediction *****\n","  Num examples = 259\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}],"source":["import numpy as np\n","import pandas as pd\n","\n","             \n","df_train = pd.read_csv(\"./input/tobacco800/df_train_tags.csv\")\n","df_test = pd.read_csv(\"./input/tobacco800/df_test_tags.csv\")\n","\n","df_train['class'] = df_train['class'].apply(lambda x: 1 if x==\"FirstPage\" else 0)\n","df_test['class'] = df_test['class'].apply(lambda x: 1 if x==\"FirstPage\" else 0)\n","\n","df_train['text'] = df_train['text'].apply(lambda x: str(x))\n","df_test['text'] = df_test['text'].apply(lambda x: str(x))\n","\n","y_pred = runBert(df_train, df_test)\n"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.metrics import roc_auc_score\n","\n","print(\"Accuracy:\", accuracy_score(df_test['class'], y_pred))\n","print(\"F1:\", f1_score(df_test['class'], y_pred, average='macro'))\n","print(\"ROC_AUC:\", roc_auc_score(df_test['class'], y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0Oo3lP83iyn","executionInfo":{"status":"ok","timestamp":1666672864849,"user_tz":180,"elapsed":21,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"4af7db14-abe1-4554-fe5b-2bd92878b011"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9073359073359073\n","F1: 0.904954128440367\n","ROC_AUC: 0.9049541284403669\n"]}]},{"cell_type":"code","source":["print(classification_report(df_test['class'], y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7OmwUESA9Ab","executionInfo":{"status":"ok","timestamp":1666672864850,"user_tz":180,"elapsed":18,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"221d3535-b6d1-4b81-dcd6-0f2e8ae3ade2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.89      0.89      0.89       109\n","           1       0.92      0.92      0.92       150\n","\n","    accuracy                           0.91       259\n","   macro avg       0.90      0.90      0.90       259\n","weighted avg       0.91      0.91      0.91       259\n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3e7541435b6e4757a19bd0cb0b572304":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff89f51d8fe345f18e34e9e2b94888a0","IPY_MODEL_e46b9cbd407842b4b91c8fd0c5a17816","IPY_MODEL_d31044c808d54663a20841ddc95c05e5"],"layout":"IPY_MODEL_01f62a059dbc42f2ae35d5fa69533fd9"}},"ff89f51d8fe345f18e34e9e2b94888a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3c3f7194e2c41ff864849b862ce12f5","placeholder":"​","style":"IPY_MODEL_a73cc058dd2645bd971df75128aaa09c","value":"Downloading: 100%"}},"e46b9cbd407842b4b91c8fd0c5a17816":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e472b7e1811741f2a36ddf11f9163ef9","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85b42b85b8a54fd58cb4744c6127d98b","value":570}},"d31044c808d54663a20841ddc95c05e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_419dc7dd615841a4809780c3d822df0d","placeholder":"​","style":"IPY_MODEL_98a8389f959445b0b331a7fc226062cf","value":" 570/570 [00:00&lt;00:00, 18.9kB/s]"}},"01f62a059dbc42f2ae35d5fa69533fd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3c3f7194e2c41ff864849b862ce12f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a73cc058dd2645bd971df75128aaa09c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e472b7e1811741f2a36ddf11f9163ef9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85b42b85b8a54fd58cb4744c6127d98b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"419dc7dd615841a4809780c3d822df0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98a8389f959445b0b331a7fc226062cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0e1520316c2449dae75697341f986a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_becd992ff540439794ebdd8984ac5115","IPY_MODEL_5afa36f2f88f4b22a0ae4ce6d80462be","IPY_MODEL_457ccd60b7754b2097a6d20ce6115a59"],"layout":"IPY_MODEL_a9880e685edc4e5abe8b4b9b2e3f88e6"}},"becd992ff540439794ebdd8984ac5115":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcedfeeb59234e83871188e09111c0d0","placeholder":"​","style":"IPY_MODEL_325e04e793aa44ec8b028fb7e3836a9d","value":"Downloading: 100%"}},"5afa36f2f88f4b22a0ae4ce6d80462be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfa7ab8f8c6140a6982de48956d82529","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d94cf27a4a44b09aa832e057e22b4c4","value":440473133}},"457ccd60b7754b2097a6d20ce6115a59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_165385d7cdf04a8cbe030a7ae2a0a787","placeholder":"​","style":"IPY_MODEL_06790d64ea7f428cbddb0479c3b5321e","value":" 440M/440M [00:16&lt;00:00, 30.1MB/s]"}},"a9880e685edc4e5abe8b4b9b2e3f88e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcedfeeb59234e83871188e09111c0d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"325e04e793aa44ec8b028fb7e3836a9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfa7ab8f8c6140a6982de48956d82529":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d94cf27a4a44b09aa832e057e22b4c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"165385d7cdf04a8cbe030a7ae2a0a787":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06790d64ea7f428cbddb0479c3b5321e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"710b50ff516746c9aba37e7e5d1697ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b04f13eda4c1414fb90567cf67e80f93","IPY_MODEL_95e0578a15324f069df02c404ba7eaf7","IPY_MODEL_a8347f47144f4b69b6409c7b7fbe15a7"],"layout":"IPY_MODEL_a04b062070134097bbfa3276e20dd77b"}},"b04f13eda4c1414fb90567cf67e80f93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14626f5e711940b4b8e87c505062bf83","placeholder":"​","style":"IPY_MODEL_78f06fe2ea414749b33e90122cb0add4","value":"Downloading: 100%"}},"95e0578a15324f069df02c404ba7eaf7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfb6e91677ef48fcb812dc9d9187949b","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0fbecae17b614bc5aef1f7d71893af8e","value":231508}},"a8347f47144f4b69b6409c7b7fbe15a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d02ff55ded514843ba9569450d99cbfb","placeholder":"​","style":"IPY_MODEL_e5b1772d2d174dfaa3821658f1d24bba","value":" 232k/232k [00:00&lt;00:00, 189kB/s]"}},"a04b062070134097bbfa3276e20dd77b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14626f5e711940b4b8e87c505062bf83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78f06fe2ea414749b33e90122cb0add4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfb6e91677ef48fcb812dc9d9187949b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fbecae17b614bc5aef1f7d71893af8e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d02ff55ded514843ba9569450d99cbfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5b1772d2d174dfaa3821658f1d24bba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b025072ad4e2434bb83d618442dcf7ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b570912d2334c3091ea72bbbec4648e","IPY_MODEL_4b9f9b97197c4f4c817d05cceb10bfa3","IPY_MODEL_cfb466074e6b435496b9c5cb4916b24a"],"layout":"IPY_MODEL_62802ba3a83545f78b058d6364a0c896"}},"1b570912d2334c3091ea72bbbec4648e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b754d51c74949edb71aee79d377cacb","placeholder":"​","style":"IPY_MODEL_5cc49d8c932f4a2ab4229b125d450392","value":"Downloading: 100%"}},"4b9f9b97197c4f4c817d05cceb10bfa3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb458ab0ac4c49a094fdb451b52efa93","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9053115ca24c4915bf77554baafe4a2b","value":28}},"cfb466074e6b435496b9c5cb4916b24a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa63e5163af1494dafec36d64cde3531","placeholder":"​","style":"IPY_MODEL_54919ffea4c64c6c9868b2220582012c","value":" 28.0/28.0 [00:00&lt;00:00, 927B/s]"}},"62802ba3a83545f78b058d6364a0c896":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b754d51c74949edb71aee79d377cacb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cc49d8c932f4a2ab4229b125d450392":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb458ab0ac4c49a094fdb451b52efa93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9053115ca24c4915bf77554baafe4a2b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa63e5163af1494dafec36d64cde3531":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54919ffea4c64c6c9868b2220582012c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}