{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42593,"status":"ok","timestamp":1666629701529,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"},"user_tz":180},"id":"GLxgv9OSFqYi","outputId":"9f1ae5db-5c80-4fc6-ef17-13d88be00f6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/LayoutQT')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84QeWKhKKG_S","executionInfo":{"status":"ok","timestamp":1666629711959,"user_tz":180,"elapsed":10434,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"909719f7-73b9-4155-a914-b9c1c70b0b6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 33.3 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 70.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 56.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXfagt2R4ysX"},"outputs":[],"source":["import torch\n","\n","# Create torch dataset\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels=None):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        if self.labels:\n","            item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqfZpHuo4oPd"},"outputs":[],"source":["def process_data_for_bert(data):\n","\n","    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","    X_tokenized = tokenizer(list(data['text']), padding=True, truncation=True, max_length=512)\n","    y = list(data['class'])\n","    \n","    dataset = Dataset(X_tokenized, y)\n","\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DVekXFaKy38u"},"outputs":[],"source":["from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import TrainingArguments, Trainer\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoModelForMaskedLM\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import train_test_split\n","\n","def runBert(df_train_dataset, df_test_dataset):\n","    \n","    batch_size=8\n","\n","    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=False )\n","\n","\n","    X_train, X_val, y_train, y_val = train_test_split(df_train_dataset['text'], df_train_dataset['class'], \n","                                                    test_size=0.2, \n","                                                    random_state=42)\n","\n","\n","    train_dataset = pd.DataFrame({'text':X_train, 'class':y_train})\n","    val_dataset = pd.DataFrame({'text':X_val, 'class':y_val})\n","\n","    \n","    \n","    train_dataset = process_data_for_bert(train_dataset)\n","    val_dataset = process_data_for_bert(val_dataset)\n","    test_dataset = process_data_for_bert(df_test_dataset)\n","\n","    # ----- 2. Fine-tune pretrained model -----#\n","    # Define Trainer parameters\n","    def compute_metrics(p):\n","        \n","        pred, labels = p\n","        pred = np.argmax(pred, axis=1)\n","\n","        accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","        recall = recall_score(y_true=labels, y_pred=pred)\n","        precision = precision_score(y_true=labels, y_pred=pred)\n","        f1 = f1_score(y_true=labels, y_pred=pred)\n","\n","        return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n","\n","    # Define Trainer\n","    args = TrainingArguments(\n","        \"./model/layoutqt\",\n","        evaluation_strategy = \"epoch\",\n","        save_strategy = \"epoch\",\n","        learning_rate=2e-5,\n","        per_device_train_batch_size=batch_size,\n","        per_device_eval_batch_size=batch_size,\n","        num_train_epochs=100,\n","        weight_decay=0.01,\n","        load_best_model_at_end=True,\n","        metric_for_best_model='f1'\n","      # optim=\"adamw_torch\"\n","    )\n","\n","    def model_init():\n","        return model\n","\n","    trainer = Trainer(\n","        model_init=model_init,\n","        args=args,\n","        train_dataset=train_dataset,\n","        eval_dataset=val_dataset,\n","        tokenizer=tokenizer,\n","        compute_metrics=compute_metrics\n","    )\n","\n","    # New code - wrap collator in a dictionary\n","    #data_collator = trainer.data_collator\n","    #trainer.data_collator = lambda data: dict(data_collator(data))\n","    # End new code\n","\n","    trainer.train()\n","\n","    # Make prediction\n","    raw_pred, _, _ = trainer.predict(test_dataset)\n","\n","    # Preprocess raw predictions\n","    y_pred = np.argmax(raw_pred, axis=1)\n","\n","    return y_pred\n","    #return roc_auc_score(df_test_dataset['class'], y_pred), f1_score(df_test_dataset['class'], y_pred, average='macro')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUTqnUToLjAH","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["792adf74c37846c49db1c6ccb97997ec","73589e9f46cb451097fb35b401043071","a8dd1b2ecabf434f8c34fc5f435aa847","f55a9d18f90b4405adc8fbd1c6680023","79d0e0334fd44bfdadbde09c23d108ed","9c323bec93e74a89a4fa7c41881d3a9b","9f5b3879925d4dc09caa4f957de1740f","94fd2d63b10840f68357b1b74bb59351","628c87e3e3414c81bd4cadd2a14e72e6","b455a7c6480f45d8a19403243585b617","4f1d5fe36f3148e39e9200879e68a4ae","0761e9624c304263884adc25225de117","0f414b8a40a74047af37232daf808d16","d6e7e9686d2e4c8c808bf64fadec4571","bc029e243bd94a96854c84a45bc33985","bfe281c6ab25452e8d14308ae3ce0612","d9cb444e14384abab93e3d2ddf550570","0a33617970bc4dfda72985719763af5d","d22520e7fae448d0a69b8eadc3aa84b8","61eef21f42024e9dbfb779f821273d15","ad4277131a644f3f8ecb9b22811af5c6","b90bde04a2874014b450501705600930","3aa849ed459947ca81d6373483db8eea","ff95e143495e40458144f28343b14820","ff89bb6e4f2d45d7aa3a20c20c84781f","522bf62f83474e86985dcda0d6d622f1","f541881ea5284301be2be4bb34e658f4","3d936de6b7bd4f3ca85a404b40cea38f","45d88f55f80d43a7ad4477351e9b91b3","cdb9a2bbc5704f63895cc56b77b90d3f","3a174bea71734c3ea30295c726bdb45c","8581e952697b42749f739a43c6b3081c","d964232b9111409eadadb1c604cfea66","de0ea0dedfc842ffa027261a01e68365","6e2fc38d28b340398ead2ff1ae66a947","bb49de3519024e51a41370924a3c12fa","8cd7434c96b245748822d54bd8cf2930","541e2356519742e1b5602c3dcb8d04c9","0a20e32137f045b5838612d61cfa3792","c84af32188b7400db91505b89d09e257","5efc80ff3ed2471cba7f0188bbb27bae","8d01a0075e7348118759ea8430012ac3","0e890720486e411fa3b448e717c3fe98","ba8a83afc19c43bb92fc78fd821ca59e"]},"outputId":"ad8d696c-3f24-4a33-eecd-741cda6644b5","executionInfo":{"status":"ok","timestamp":1666639488994,"user_tz":180,"elapsed":9771901,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"792adf74c37846c49db1c6ccb97997ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0761e9624c304263884adc25225de117"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aa849ed459947ca81d6373483db8eea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de0ea0dedfc842ffa027261a01e68365"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 824\n","  Num Epochs = 100\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 10300\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10300' max='10300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10300/10300 2:41:53, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.405177</td>\n","      <td>0.835749</td>\n","      <td>0.820312</td>\n","      <td>0.905172</td>\n","      <td>0.860656</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.335200</td>\n","      <td>0.898551</td>\n","      <td>0.913043</td>\n","      <td>0.905172</td>\n","      <td>0.909091</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.397784</td>\n","      <td>0.888889</td>\n","      <td>0.872000</td>\n","      <td>0.939655</td>\n","      <td>0.904564</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.386799</td>\n","      <td>0.903382</td>\n","      <td>0.893443</td>\n","      <td>0.939655</td>\n","      <td>0.915966</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.327700</td>\n","      <td>0.479933</td>\n","      <td>0.879227</td>\n","      <td>0.864000</td>\n","      <td>0.931034</td>\n","      <td>0.896266</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.327700</td>\n","      <td>0.590824</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.327700</td>\n","      <td>0.687164</td>\n","      <td>0.874396</td>\n","      <td>0.881356</td>\n","      <td>0.896552</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.327700</td>\n","      <td>0.574801</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.327700</td>\n","      <td>0.883987</td>\n","      <td>0.864734</td>\n","      <td>0.879310</td>\n","      <td>0.879310</td>\n","      <td>0.879310</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.097700</td>\n","      <td>0.935717</td>\n","      <td>0.864734</td>\n","      <td>0.843750</td>\n","      <td>0.931034</td>\n","      <td>0.885246</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.097700</td>\n","      <td>0.955789</td>\n","      <td>0.864734</td>\n","      <td>0.860656</td>\n","      <td>0.905172</td>\n","      <td>0.882353</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.097700</td>\n","      <td>1.041163</td>\n","      <td>0.855072</td>\n","      <td>0.858333</td>\n","      <td>0.887931</td>\n","      <td>0.872881</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.097700</td>\n","      <td>0.982071</td>\n","      <td>0.874396</td>\n","      <td>0.857143</td>\n","      <td>0.931034</td>\n","      <td>0.892562</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.097700</td>\n","      <td>1.106936</td>\n","      <td>0.859903</td>\n","      <td>0.865546</td>\n","      <td>0.887931</td>\n","      <td>0.876596</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.024000</td>\n","      <td>1.033686</td>\n","      <td>0.874396</td>\n","      <td>0.875000</td>\n","      <td>0.905172</td>\n","      <td>0.889831</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.024000</td>\n","      <td>1.075282</td>\n","      <td>0.874396</td>\n","      <td>0.857143</td>\n","      <td>0.931034</td>\n","      <td>0.892562</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.024000</td>\n","      <td>1.183954</td>\n","      <td>0.864734</td>\n","      <td>0.843750</td>\n","      <td>0.931034</td>\n","      <td>0.885246</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.024000</td>\n","      <td>1.057694</td>\n","      <td>0.884058</td>\n","      <td>0.883333</td>\n","      <td>0.913793</td>\n","      <td>0.898305</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.024000</td>\n","      <td>1.017218</td>\n","      <td>0.874396</td>\n","      <td>0.857143</td>\n","      <td>0.931034</td>\n","      <td>0.892562</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.006200</td>\n","      <td>0.992189</td>\n","      <td>0.879227</td>\n","      <td>0.864000</td>\n","      <td>0.931034</td>\n","      <td>0.896266</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.006200</td>\n","      <td>1.006920</td>\n","      <td>0.879227</td>\n","      <td>0.864000</td>\n","      <td>0.931034</td>\n","      <td>0.896266</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.006200</td>\n","      <td>1.024262</td>\n","      <td>0.888889</td>\n","      <td>0.872000</td>\n","      <td>0.939655</td>\n","      <td>0.904564</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.006200</td>\n","      <td>1.025060</td>\n","      <td>0.893720</td>\n","      <td>0.879032</td>\n","      <td>0.939655</td>\n","      <td>0.908333</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.006200</td>\n","      <td>1.041684</td>\n","      <td>0.888889</td>\n","      <td>0.872000</td>\n","      <td>0.939655</td>\n","      <td>0.904564</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.003800</td>\n","      <td>1.053930</td>\n","      <td>0.888889</td>\n","      <td>0.872000</td>\n","      <td>0.939655</td>\n","      <td>0.904564</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.003800</td>\n","      <td>1.077441</td>\n","      <td>0.884058</td>\n","      <td>0.865079</td>\n","      <td>0.939655</td>\n","      <td>0.900826</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.003800</td>\n","      <td>1.059948</td>\n","      <td>0.888889</td>\n","      <td>0.878049</td>\n","      <td>0.931034</td>\n","      <td>0.903766</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.003800</td>\n","      <td>1.060235</td>\n","      <td>0.888889</td>\n","      <td>0.884298</td>\n","      <td>0.922414</td>\n","      <td>0.902954</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.003800</td>\n","      <td>1.121276</td>\n","      <td>0.884058</td>\n","      <td>0.870968</td>\n","      <td>0.931034</td>\n","      <td>0.900000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.003000</td>\n","      <td>1.120884</td>\n","      <td>0.884058</td>\n","      <td>0.870968</td>\n","      <td>0.931034</td>\n","      <td>0.900000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.003000</td>\n","      <td>1.134798</td>\n","      <td>0.884058</td>\n","      <td>0.870968</td>\n","      <td>0.931034</td>\n","      <td>0.900000</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.003000</td>\n","      <td>1.187127</td>\n","      <td>0.859903</td>\n","      <td>0.853659</td>\n","      <td>0.905172</td>\n","      <td>0.878661</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.003000</td>\n","      <td>1.295575</td>\n","      <td>0.845411</td>\n","      <td>0.850000</td>\n","      <td>0.879310</td>\n","      <td>0.864407</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.026400</td>\n","      <td>1.257488</td>\n","      <td>0.869565</td>\n","      <td>0.850394</td>\n","      <td>0.931034</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.026400</td>\n","      <td>1.274452</td>\n","      <td>0.869565</td>\n","      <td>0.850394</td>\n","      <td>0.931034</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.026400</td>\n","      <td>1.089208</td>\n","      <td>0.888889</td>\n","      <td>0.884298</td>\n","      <td>0.922414</td>\n","      <td>0.902954</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.026400</td>\n","      <td>1.260342</td>\n","      <td>0.869565</td>\n","      <td>0.850394</td>\n","      <td>0.931034</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.026400</td>\n","      <td>1.274742</td>\n","      <td>0.869565</td>\n","      <td>0.850394</td>\n","      <td>0.931034</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.008000</td>\n","      <td>1.282211</td>\n","      <td>0.869565</td>\n","      <td>0.850394</td>\n","      <td>0.931034</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.008000</td>\n","      <td>1.345311</td>\n","      <td>0.850242</td>\n","      <td>0.834646</td>\n","      <td>0.913793</td>\n","      <td>0.872428</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.008000</td>\n","      <td>1.370344</td>\n","      <td>0.864734</td>\n","      <td>0.843750</td>\n","      <td>0.931034</td>\n","      <td>0.885246</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.008000</td>\n","      <td>1.216745</td>\n","      <td>0.874396</td>\n","      <td>0.857143</td>\n","      <td>0.931034</td>\n","      <td>0.892562</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.008000</td>\n","      <td>1.165275</td>\n","      <td>0.879227</td>\n","      <td>0.864000</td>\n","      <td>0.931034</td>\n","      <td>0.896266</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.012900</td>\n","      <td>1.198202</td>\n","      <td>0.879227</td>\n","      <td>0.864000</td>\n","      <td>0.931034</td>\n","      <td>0.896266</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.012900</td>\n","      <td>1.283299</td>\n","      <td>0.864734</td>\n","      <td>0.872881</td>\n","      <td>0.887931</td>\n","      <td>0.880342</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.012900</td>\n","      <td>1.270473</td>\n","      <td>0.874396</td>\n","      <td>0.862903</td>\n","      <td>0.922414</td>\n","      <td>0.891667</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.012900</td>\n","      <td>1.254142</td>\n","      <td>0.884058</td>\n","      <td>0.877049</td>\n","      <td>0.922414</td>\n","      <td>0.899160</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.012900</td>\n","      <td>1.261114</td>\n","      <td>0.884058</td>\n","      <td>0.877049</td>\n","      <td>0.922414</td>\n","      <td>0.899160</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.003200</td>\n","      <td>1.271856</td>\n","      <td>0.884058</td>\n","      <td>0.877049</td>\n","      <td>0.922414</td>\n","      <td>0.899160</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.003200</td>\n","      <td>1.279133</td>\n","      <td>0.884058</td>\n","      <td>0.877049</td>\n","      <td>0.922414</td>\n","      <td>0.899160</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.003200</td>\n","      <td>1.284922</td>\n","      <td>0.884058</td>\n","      <td>0.877049</td>\n","      <td>0.922414</td>\n","      <td>0.899160</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.003200</td>\n","      <td>1.288853</td>\n","      <td>0.884058</td>\n","      <td>0.877049</td>\n","      <td>0.922414</td>\n","      <td>0.899160</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.003200</td>\n","      <td>1.298066</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.002700</td>\n","      <td>1.304007</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.002700</td>\n","      <td>1.312622</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.002700</td>\n","      <td>1.320636</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.002700</td>\n","      <td>1.323361</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.002700</td>\n","      <td>1.330199</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.003200</td>\n","      <td>1.332331</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.003200</td>\n","      <td>1.334296</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.003200</td>\n","      <td>1.400101</td>\n","      <td>0.855072</td>\n","      <td>0.883929</td>\n","      <td>0.853448</td>\n","      <td>0.868421</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.003200</td>\n","      <td>1.296216</td>\n","      <td>0.879227</td>\n","      <td>0.869919</td>\n","      <td>0.922414</td>\n","      <td>0.895397</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.003200</td>\n","      <td>1.344481</td>\n","      <td>0.874396</td>\n","      <td>0.846154</td>\n","      <td>0.948276</td>\n","      <td>0.894309</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.008900</td>\n","      <td>1.350988</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.008900</td>\n","      <td>1.360351</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.008900</td>\n","      <td>1.367559</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.008900</td>\n","      <td>1.372408</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.003400</td>\n","      <td>1.378049</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.003400</td>\n","      <td>1.383768</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.003400</td>\n","      <td>1.387127</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.003400</td>\n","      <td>1.397107</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.003400</td>\n","      <td>1.413696</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.003000</td>\n","      <td>1.415609</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.003000</td>\n","      <td>1.418960</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.003000</td>\n","      <td>1.422730</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.003000</td>\n","      <td>1.426623</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.003000</td>\n","      <td>1.427958</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.002800</td>\n","      <td>1.431014</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.002800</td>\n","      <td>1.433604</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.002800</td>\n","      <td>1.436927</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.002800</td>\n","      <td>1.439630</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.002800</td>\n","      <td>1.442961</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.002500</td>\n","      <td>1.446049</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.002500</td>\n","      <td>1.448311</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.002500</td>\n","      <td>1.450076</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.002500</td>\n","      <td>1.452032</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.002500</td>\n","      <td>1.453157</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.003800</td>\n","      <td>1.455342</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.003800</td>\n","      <td>1.457668</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.003800</td>\n","      <td>1.459679</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.003800</td>\n","      <td>1.461960</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.003800</td>\n","      <td>1.463585</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.002600</td>\n","      <td>1.465732</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.002600</td>\n","      <td>1.466389</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.002600</td>\n","      <td>1.467415</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.002600</td>\n","      <td>1.467691</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.002600</td>\n","      <td>1.468307</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.003200</td>\n","      <td>1.468696</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.003200</td>\n","      <td>1.468976</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.003200</td>\n","      <td>1.469051</td>\n","      <td>0.879227</td>\n","      <td>0.876033</td>\n","      <td>0.913793</td>\n","      <td>0.894515</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-103\n","Configuration saved in ./model/layoutqt/checkpoint-103/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-103/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-103/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-103/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-206\n","Configuration saved in ./model/layoutqt/checkpoint-206/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-206/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-206/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-206/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-309\n","Configuration saved in ./model/layoutqt/checkpoint-309/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-309/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-309/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-309/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-412\n","Configuration saved in ./model/layoutqt/checkpoint-412/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-412/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-412/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-412/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-515\n","Configuration saved in ./model/layoutqt/checkpoint-515/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-515/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-515/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-515/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-618\n","Configuration saved in ./model/layoutqt/checkpoint-618/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-618/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-618/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-618/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-721\n","Configuration saved in ./model/layoutqt/checkpoint-721/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-721/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-721/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-721/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-824\n","Configuration saved in ./model/layoutqt/checkpoint-824/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-824/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-824/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-824/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-927\n","Configuration saved in ./model/layoutqt/checkpoint-927/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-927/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-927/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-927/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1030\n","Configuration saved in ./model/layoutqt/checkpoint-1030/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1030/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1030/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1030/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1133\n","Configuration saved in ./model/layoutqt/checkpoint-1133/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1133/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1133/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1133/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1236\n","Configuration saved in ./model/layoutqt/checkpoint-1236/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1236/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1236/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1236/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1339\n","Configuration saved in ./model/layoutqt/checkpoint-1339/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1339/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1339/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1339/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1442\n","Configuration saved in ./model/layoutqt/checkpoint-1442/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1442/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1442/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1442/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1545\n","Configuration saved in ./model/layoutqt/checkpoint-1545/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1545/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1545/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1545/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1648\n","Configuration saved in ./model/layoutqt/checkpoint-1648/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1648/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1648/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1648/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1751\n","Configuration saved in ./model/layoutqt/checkpoint-1751/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1751/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1751/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1751/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1854\n","Configuration saved in ./model/layoutqt/checkpoint-1854/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1854/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1854/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1854/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-1957\n","Configuration saved in ./model/layoutqt/checkpoint-1957/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-1957/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-1957/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-1957/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2060\n","Configuration saved in ./model/layoutqt/checkpoint-2060/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2060/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2060/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2060/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2163\n","Configuration saved in ./model/layoutqt/checkpoint-2163/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2163/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2163/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2163/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2266\n","Configuration saved in ./model/layoutqt/checkpoint-2266/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2266/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2266/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2266/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2369\n","Configuration saved in ./model/layoutqt/checkpoint-2369/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2369/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2369/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2369/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2472\n","Configuration saved in ./model/layoutqt/checkpoint-2472/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2472/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2472/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2472/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2575\n","Configuration saved in ./model/layoutqt/checkpoint-2575/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2575/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2575/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2575/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2678\n","Configuration saved in ./model/layoutqt/checkpoint-2678/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2678/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2678/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2678/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2781\n","Configuration saved in ./model/layoutqt/checkpoint-2781/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2781/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2781/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2781/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2884\n","Configuration saved in ./model/layoutqt/checkpoint-2884/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2884/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2884/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2884/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-2987\n","Configuration saved in ./model/layoutqt/checkpoint-2987/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-2987/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-2987/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-2987/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3090\n","Configuration saved in ./model/layoutqt/checkpoint-3090/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3090/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3090/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3090/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3193\n","Configuration saved in ./model/layoutqt/checkpoint-3193/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3193/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3193/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3193/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3296\n","Configuration saved in ./model/layoutqt/checkpoint-3296/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3296/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3296/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3296/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3399\n","Configuration saved in ./model/layoutqt/checkpoint-3399/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3399/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3399/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3399/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3502\n","Configuration saved in ./model/layoutqt/checkpoint-3502/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3502/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3502/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3502/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3605\n","Configuration saved in ./model/layoutqt/checkpoint-3605/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3605/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3605/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3605/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3708\n","Configuration saved in ./model/layoutqt/checkpoint-3708/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3708/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3708/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3708/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3811\n","Configuration saved in ./model/layoutqt/checkpoint-3811/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3811/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3811/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3811/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-3914\n","Configuration saved in ./model/layoutqt/checkpoint-3914/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-3914/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-3914/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-3914/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4017\n","Configuration saved in ./model/layoutqt/checkpoint-4017/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4017/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4017/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4017/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4120\n","Configuration saved in ./model/layoutqt/checkpoint-4120/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4120/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4120/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4120/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4223\n","Configuration saved in ./model/layoutqt/checkpoint-4223/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4223/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4223/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4223/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4326\n","Configuration saved in ./model/layoutqt/checkpoint-4326/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4326/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4326/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4326/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4429\n","Configuration saved in ./model/layoutqt/checkpoint-4429/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4429/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4429/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4429/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4532\n","Configuration saved in ./model/layoutqt/checkpoint-4532/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4532/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4532/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4532/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4635\n","Configuration saved in ./model/layoutqt/checkpoint-4635/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4635/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4635/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4635/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4738\n","Configuration saved in ./model/layoutqt/checkpoint-4738/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4738/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4738/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4738/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4841\n","Configuration saved in ./model/layoutqt/checkpoint-4841/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4841/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4841/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4841/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-4944\n","Configuration saved in ./model/layoutqt/checkpoint-4944/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-4944/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-4944/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-4944/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5047\n","Configuration saved in ./model/layoutqt/checkpoint-5047/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5047/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5047/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5047/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5150\n","Configuration saved in ./model/layoutqt/checkpoint-5150/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5150/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5150/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5253\n","Configuration saved in ./model/layoutqt/checkpoint-5253/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5253/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5253/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5253/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5356\n","Configuration saved in ./model/layoutqt/checkpoint-5356/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5356/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5356/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5356/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5459\n","Configuration saved in ./model/layoutqt/checkpoint-5459/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5459/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5459/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5459/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5562\n","Configuration saved in ./model/layoutqt/checkpoint-5562/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5562/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5562/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5562/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5665\n","Configuration saved in ./model/layoutqt/checkpoint-5665/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5665/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5665/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5665/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5768\n","Configuration saved in ./model/layoutqt/checkpoint-5768/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5768/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5768/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5768/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5871\n","Configuration saved in ./model/layoutqt/checkpoint-5871/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5871/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5871/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5871/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-5974\n","Configuration saved in ./model/layoutqt/checkpoint-5974/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-5974/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-5974/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-5974/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-6077\n","Configuration saved in ./model/layoutqt/checkpoint-6077/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-6077/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-6077/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-6077/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-6180\n","Configuration saved in ./model/layoutqt/checkpoint-6180/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-6180/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-6180/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-6180/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-6283\n","Configuration saved in ./model/layoutqt/checkpoint-6283/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-6283/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-6283/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-6283/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-6386\n","Configuration saved in ./model/layoutqt/checkpoint-6386/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-6386/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-6386/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-6386/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-6489\n","Configuration saved in ./model/layoutqt/checkpoint-6489/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-6489/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-6489/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-6489/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-6592\n","Configuration saved in ./model/layoutqt/checkpoint-6592/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-6592/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-6592/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-6592/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-6695\n","Configuration saved in ./model/layoutqt/checkpoint-6695/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-6695/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-6695/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-6695/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-6798\n","Configuration saved in ./model/layoutqt/checkpoint-6798/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-6798/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-6798/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-6798/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-6901\n","Configuration saved in ./model/layoutqt/checkpoint-6901/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-6901/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-6901/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-6901/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-7004\n","Configuration saved in ./model/layoutqt/checkpoint-7004/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-7004/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-7004/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-7004/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-7107\n","Configuration saved in ./model/layoutqt/checkpoint-7107/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-7107/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-7107/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-7107/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-7210\n","Configuration saved in ./model/layoutqt/checkpoint-7210/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-7210/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-7210/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-7210/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-7313\n","Configuration saved in ./model/layoutqt/checkpoint-7313/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-7313/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-7313/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-7313/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-7416\n","Configuration saved in ./model/layoutqt/checkpoint-7416/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-7416/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-7416/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-7416/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-7519\n","Configuration saved in ./model/layoutqt/checkpoint-7519/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-7519/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-7519/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-7519/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-7622\n","Configuration saved in ./model/layoutqt/checkpoint-7622/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-7622/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-7622/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-7622/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-7725\n","Configuration saved in ./model/layoutqt/checkpoint-7725/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-7725/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-7725/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-7725/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-7828\n","Configuration saved in ./model/layoutqt/checkpoint-7828/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-7828/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-7828/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-7828/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-7931\n","Configuration saved in ./model/layoutqt/checkpoint-7931/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-7931/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-7931/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-7931/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-8034\n","Configuration saved in ./model/layoutqt/checkpoint-8034/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-8034/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-8034/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-8034/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-8137\n","Configuration saved in ./model/layoutqt/checkpoint-8137/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-8137/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-8137/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-8137/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-8240\n","Configuration saved in ./model/layoutqt/checkpoint-8240/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-8240/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-8240/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-8240/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-8343\n","Configuration saved in ./model/layoutqt/checkpoint-8343/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-8343/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-8343/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-8343/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-8446\n","Configuration saved in ./model/layoutqt/checkpoint-8446/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-8446/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-8446/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-8446/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-8549\n","Configuration saved in ./model/layoutqt/checkpoint-8549/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-8549/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-8549/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-8549/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-8652\n","Configuration saved in ./model/layoutqt/checkpoint-8652/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-8652/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-8652/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-8652/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-8755\n","Configuration saved in ./model/layoutqt/checkpoint-8755/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-8755/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-8755/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-8755/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-8858\n","Configuration saved in ./model/layoutqt/checkpoint-8858/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-8858/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-8858/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-8858/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-8961\n","Configuration saved in ./model/layoutqt/checkpoint-8961/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-8961/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-8961/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-8961/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-9064\n","Configuration saved in ./model/layoutqt/checkpoint-9064/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-9064/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-9064/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-9064/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-9167\n","Configuration saved in ./model/layoutqt/checkpoint-9167/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-9167/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-9167/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-9167/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-9270\n","Configuration saved in ./model/layoutqt/checkpoint-9270/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-9270/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-9270/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-9270/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-9373\n","Configuration saved in ./model/layoutqt/checkpoint-9373/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-9373/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-9373/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-9373/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-9476\n","Configuration saved in ./model/layoutqt/checkpoint-9476/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-9476/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-9476/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-9476/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-9579\n","Configuration saved in ./model/layoutqt/checkpoint-9579/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-9579/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-9579/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-9579/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-9682\n","Configuration saved in ./model/layoutqt/checkpoint-9682/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-9682/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-9682/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-9682/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-9785\n","Configuration saved in ./model/layoutqt/checkpoint-9785/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-9785/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-9785/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-9785/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-9888\n","Configuration saved in ./model/layoutqt/checkpoint-9888/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-9888/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-9888/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-9888/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-9991\n","Configuration saved in ./model/layoutqt/checkpoint-9991/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-9991/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-9991/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-9991/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-10094\n","Configuration saved in ./model/layoutqt/checkpoint-10094/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-10094/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-10094/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-10094/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-10197\n","Configuration saved in ./model/layoutqt/checkpoint-10197/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-10197/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-10197/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-10197/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 207\n","  Batch size = 8\n","Saving model checkpoint to ./model/layoutqt/checkpoint-10300\n","Configuration saved in ./model/layoutqt/checkpoint-10300/config.json\n","Model weights saved in ./model/layoutqt/checkpoint-10300/pytorch_model.bin\n","tokenizer config file saved in ./model/layoutqt/checkpoint-10300/tokenizer_config.json\n","Special tokens file saved in ./model/layoutqt/checkpoint-10300/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from ./model/layoutqt/checkpoint-412 (score: 0.9159663865546218).\n","***** Running Prediction *****\n","  Num examples = 259\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}],"source":["import numpy as np\n","import pandas as pd\n","\n","             \n","df_train = pd.read_csv(\"./input/tobacco800/df_train.csv\")\n","df_test = pd.read_csv(\"./input/tobacco800/df_test.csv\")\n","\n","df_train['class'] = df_train['class'].apply(lambda x: 1 if x==\"FirstPage\" else 0)\n","df_test['class'] = df_test['class'].apply(lambda x: 1 if x==\"FirstPage\" else 0)\n","\n","df_train['text'] = df_train['text'].apply(lambda x: str(x))\n","df_test['text'] = df_test['text'].apply(lambda x: str(x))\n","\n","y_pred = runBert(df_train, df_test)\n"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.metrics import roc_auc_score\n","\n","print(\"Accuracy:\", accuracy_score(df_test['class'], y_pred))\n","print(\"F1:\", f1_score(df_test['class'], y_pred, average='macro'))\n","print(\"ROC_AUC:\", roc_auc_score(df_test['class'], y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0Oo3lP83iyn","executionInfo":{"status":"ok","timestamp":1666639488994,"user_tz":180,"elapsed":15,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"ba2574c0-c2a6-491e-a578-daa07600ae32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9227799227799228\n","F1: 0.9207951070336391\n","ROC_AUC: 0.9207951070336392\n"]}]},{"cell_type":"code","source":["print(classification_report(df_test['class'], y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7OmwUESA9Ab","executionInfo":{"status":"ok","timestamp":1666639488994,"user_tz":180,"elapsed":12,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"662095a0-58c5-4009-e8b8-d42c96ded82e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.91      0.91      0.91       109\n","           1       0.93      0.93      0.93       150\n","\n","    accuracy                           0.92       259\n","   macro avg       0.92      0.92      0.92       259\n","weighted avg       0.92      0.92      0.92       259\n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"792adf74c37846c49db1c6ccb97997ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73589e9f46cb451097fb35b401043071","IPY_MODEL_a8dd1b2ecabf434f8c34fc5f435aa847","IPY_MODEL_f55a9d18f90b4405adc8fbd1c6680023"],"layout":"IPY_MODEL_79d0e0334fd44bfdadbde09c23d108ed"}},"73589e9f46cb451097fb35b401043071":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c323bec93e74a89a4fa7c41881d3a9b","placeholder":"​","style":"IPY_MODEL_9f5b3879925d4dc09caa4f957de1740f","value":"Downloading: 100%"}},"a8dd1b2ecabf434f8c34fc5f435aa847":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_94fd2d63b10840f68357b1b74bb59351","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_628c87e3e3414c81bd4cadd2a14e72e6","value":570}},"f55a9d18f90b4405adc8fbd1c6680023":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b455a7c6480f45d8a19403243585b617","placeholder":"​","style":"IPY_MODEL_4f1d5fe36f3148e39e9200879e68a4ae","value":" 570/570 [00:00&lt;00:00, 15.8kB/s]"}},"79d0e0334fd44bfdadbde09c23d108ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c323bec93e74a89a4fa7c41881d3a9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f5b3879925d4dc09caa4f957de1740f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94fd2d63b10840f68357b1b74bb59351":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"628c87e3e3414c81bd4cadd2a14e72e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b455a7c6480f45d8a19403243585b617":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f1d5fe36f3148e39e9200879e68a4ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0761e9624c304263884adc25225de117":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f414b8a40a74047af37232daf808d16","IPY_MODEL_d6e7e9686d2e4c8c808bf64fadec4571","IPY_MODEL_bc029e243bd94a96854c84a45bc33985"],"layout":"IPY_MODEL_bfe281c6ab25452e8d14308ae3ce0612"}},"0f414b8a40a74047af37232daf808d16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9cb444e14384abab93e3d2ddf550570","placeholder":"​","style":"IPY_MODEL_0a33617970bc4dfda72985719763af5d","value":"Downloading: 100%"}},"d6e7e9686d2e4c8c808bf64fadec4571":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d22520e7fae448d0a69b8eadc3aa84b8","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61eef21f42024e9dbfb779f821273d15","value":440473133}},"bc029e243bd94a96854c84a45bc33985":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad4277131a644f3f8ecb9b22811af5c6","placeholder":"​","style":"IPY_MODEL_b90bde04a2874014b450501705600930","value":" 440M/440M [00:10&lt;00:00, 18.9MB/s]"}},"bfe281c6ab25452e8d14308ae3ce0612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9cb444e14384abab93e3d2ddf550570":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a33617970bc4dfda72985719763af5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d22520e7fae448d0a69b8eadc3aa84b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61eef21f42024e9dbfb779f821273d15":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad4277131a644f3f8ecb9b22811af5c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b90bde04a2874014b450501705600930":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3aa849ed459947ca81d6373483db8eea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff95e143495e40458144f28343b14820","IPY_MODEL_ff89bb6e4f2d45d7aa3a20c20c84781f","IPY_MODEL_522bf62f83474e86985dcda0d6d622f1"],"layout":"IPY_MODEL_f541881ea5284301be2be4bb34e658f4"}},"ff95e143495e40458144f28343b14820":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d936de6b7bd4f3ca85a404b40cea38f","placeholder":"​","style":"IPY_MODEL_45d88f55f80d43a7ad4477351e9b91b3","value":"Downloading: 100%"}},"ff89bb6e4f2d45d7aa3a20c20c84781f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdb9a2bbc5704f63895cc56b77b90d3f","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a174bea71734c3ea30295c726bdb45c","value":231508}},"522bf62f83474e86985dcda0d6d622f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8581e952697b42749f739a43c6b3081c","placeholder":"​","style":"IPY_MODEL_d964232b9111409eadadb1c604cfea66","value":" 232k/232k [00:00&lt;00:00, 233kB/s]"}},"f541881ea5284301be2be4bb34e658f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d936de6b7bd4f3ca85a404b40cea38f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45d88f55f80d43a7ad4477351e9b91b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdb9a2bbc5704f63895cc56b77b90d3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a174bea71734c3ea30295c726bdb45c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8581e952697b42749f739a43c6b3081c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d964232b9111409eadadb1c604cfea66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de0ea0dedfc842ffa027261a01e68365":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e2fc38d28b340398ead2ff1ae66a947","IPY_MODEL_bb49de3519024e51a41370924a3c12fa","IPY_MODEL_8cd7434c96b245748822d54bd8cf2930"],"layout":"IPY_MODEL_541e2356519742e1b5602c3dcb8d04c9"}},"6e2fc38d28b340398ead2ff1ae66a947":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a20e32137f045b5838612d61cfa3792","placeholder":"​","style":"IPY_MODEL_c84af32188b7400db91505b89d09e257","value":"Downloading: 100%"}},"bb49de3519024e51a41370924a3c12fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5efc80ff3ed2471cba7f0188bbb27bae","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d01a0075e7348118759ea8430012ac3","value":28}},"8cd7434c96b245748822d54bd8cf2930":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e890720486e411fa3b448e717c3fe98","placeholder":"​","style":"IPY_MODEL_ba8a83afc19c43bb92fc78fd821ca59e","value":" 28.0/28.0 [00:00&lt;00:00, 159B/s]"}},"541e2356519742e1b5602c3dcb8d04c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a20e32137f045b5838612d61cfa3792":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c84af32188b7400db91505b89d09e257":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5efc80ff3ed2471cba7f0188bbb27bae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d01a0075e7348118759ea8430012ac3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e890720486e411fa3b448e717c3fe98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba8a83afc19c43bb92fc78fd821ca59e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}